{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Introducción__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn (sklearn) es una biblioteca de Python diseñada para resolver problemas de machine learning. Está basada en otras bibliotecas científicas como NumPy, SciPy y matplotlib, y proporciona herramientas para crear, evaluar y mejorar modelos de machine learning de manera simple y eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conceptos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Estimadores.__\n",
    "\n",
    "Todos los algoritmos en scikit-learn están implementados como clases, conocidas como estimadores. Es un objeto que puede aprender de los datos, es decir, ajustar un modelo, usando el método .fit(). Un ejemplo es LinearRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Transformadores.__\n",
    "\n",
    "Son estimadores que modifican o transforman los datos. Por ejemplo, .fit(), que aprende a partir de los datos de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "__Modelos supervisados__\n",
    "\n",
    "- Clasificación. Están diseñados para problemas donde las etiquetas son categóricas. \n",
    "- Regresión. Están diseñados para problemas donde las etiquetas son numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Modelos no supervisados__\n",
    "\n",
    "- Clustering. Agrupa puntos de datos en diferentes clústeres. Ejemplos: Kmeans, DBSCAN.\n",
    "- Reducción de dimensionalidad. Reduce la cantidad de variables de entrada. Ejemplos: PCA, TruncatedSVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = load_iris()\n",
    "\n",
    "# Carga el dataset 'iris', muy popular.\n",
    "# Tiene información de 150 flores de la especie Iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definir variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Características (Features).__ Son los atributos o propiedades que describen un dato o una instancia en el dataset. Estas características son las que el algoritmo de machine learning utiliza para hacer predicciones o tomar decisiones. Componen la variable X. En esencia, es la información que se utiliza para entrenar el modelo. Se representan generalmente como columnas en un dataset.\n",
    "Cada característica es una variable que describe algún aspecto del dato. Por ejemplo, si estás construyendo un modelo para predecir el precio de una casa, las características podrían ser:\n",
    "- Tamaño de la casa (en metros cuadrados).\n",
    "- Número de habitaciones.\n",
    "- Ubicación.\n",
    "- Antigüedad de la casa (en años)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Data.data    # Variables predictoras.\n",
    "\n",
    "# Data.data contiene los datos a predecir.\n",
    "# Es un array multidimensional en caso de ser muchas variables.\n",
    "# Cada columna corresponde a una feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Etiquetas (Labels).__ Son las respuestas o resultados que queremos predecir o clasificar. En otras palabras, la etiqueta es lo que el modelo tiene que aprender a predecir basándose en las características. Son los datos de salida o respuestas que intentas predecir con el modelo. En esencia, es la variable objetivo que queremos predecir.\n",
    "Si estamos construyendo un modelo para clasificar si un coche es \"Eficiente\" o \"No eficiente\" basado en sus características, la etiqueta podría ser:\n",
    "- Eficiente.\n",
    "- No eficiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Data.target  # Variables a predecir.\n",
    "\n",
    "# Es un array de tantas columnas como variables haya.\n",
    "# Cada columna corresponde a unn label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obtener los nombres de las variables del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.feature_names\n",
    "\n",
    "# Obtiene nombres de variables predictoras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obtener los nombres de las clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.target_names\n",
    "\n",
    "# Obtiene nombres de variables a predecir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### División del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selección y entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = LogisticRegression()\n",
    "Model.fit(X_Train, Y_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = Model.predict(X_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy = accuracy_score(Y_Test, Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {Accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Preprocesamiento de datos__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos a menudo requieren ser transformados o normalizados antes de ser utilizados en un modelo de machine learning. Existen varios métodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Escalado de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Scaled = Scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Codificación de variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Encoded = Encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Validación cruzada__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es una técnica para evaluar el rendimiento de un modelo y evitar problemas de sobreajuste. El proceso divide el conjunto de datos en varias particiones, entrena el modelo en diferentes subconjuntos y promedia los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross_Val_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scores = cross_val_score(Model, X, y, cv = 5)\n",
    "\n",
    "# cv = número de particiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cross-validation scores: {Scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
